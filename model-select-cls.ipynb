{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection - Classification\n",
    "\n",
    "Testing out different classification models and selecting what seems to perform the best. (I honestly have no idea what I'm doing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# suppress future warnings for xgboost and unsupported kanji unicode in plots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "data_dir = os.path.abspath('data')\n",
    "\n",
    "# today = datetime.today().strftime('%Y%m%d')\n",
    "today = datetime.strptime('2022-09-27', '%Y-%m-%d').strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util to display general classifier performance\n",
    "def print_model_results(y_test, y_pred):\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=6))\n",
    "    # precision: ratio of true positives to sum of true and false positives\n",
    "    # recall:    ratio of true positives to sum of true positives and false negatives\n",
    "    # f1 score:  weighted harmonic mean of precision and recall; closer to one, more accurate\n",
    "    # support:   number of occurrences in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encode a column of categorical data\n",
    "def binary_encode(df: DataFrame, col: str) -> DataFrame:\n",
    "    try:\n",
    "        df[col] = df[col].apply(json.loads) # deserialize JSON array\n",
    "    except ValueError: pass\n",
    "    except TypeError:  pass\n",
    "\n",
    "    encoded = df.explode(col) # expand categorical data into rows\n",
    "    encoded = pd.concat([df, pd.get_dummies(encoded[col], prefix=col, prefix_sep='_')], axis=1) # convert to indicators\n",
    "    encoded = encoded.groupby('id').max().reset_index() # squash rows\n",
    "    return encoded.drop([col], axis=1) # drop encoded column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsing 1-10 score to [BAD,EH,GOOD] rating...to make prediction easier\n",
    "def score_to_rating(score: int) -> str:\n",
    "    if score <= 5:\n",
    "        return 'BAD'\n",
    "    elif score >= 6 and score <= 7:\n",
    "        return 'EH'\n",
    "    return 'GOOD'\n",
    "\n",
    "def would_recommend(score: int) -> bool:\n",
    "    if score < 7:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = pd.read_csv(os.path.join(data_dir, f'user-{today}-enriched.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine less common studios to OTHER\n",
    "\n",
    "# rare_studios = enriched_df.filter(['id','studios']).value_counts().reset_index(name='count').query('count == 1')['id']\n",
    "# enriched_df['studios'] = enriched_df['studios'].apply(lambda s: 'OTHER' if s in rare_studios else s)\n",
    "\n",
    "# Note: didn't seem to help much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['genres', 'studios', 'tags', 'source', 'season_year', 'format']\n",
    "\n",
    "# drop unused features\n",
    "enriched_df.drop(['episodes', 'season'], axis=1, inplace=True)\n",
    "\n",
    "# condense scores to three rating levels\n",
    "enriched_df['recommend'] = enriched_df['score'].apply(would_recommend)\n",
    "enriched_df.drop(['score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 458)\n"
     ]
    }
   ],
   "source": [
    "# Binary encodes tags,genres,studios. Binary encoding eliminates possible\n",
    "# data leaks that occur with one-hot encoding since it retains one row per entity.\n",
    "\n",
    "# binary encode each categorical column\n",
    "for col in cols:\n",
    "    enriched_df = binary_encode(enriched_df, col)\n",
    "enriched_df.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "print(enriched_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (333, 457) ; y_train = (333,)\n",
      "X_valid = (111, 457) ; y_valid = (111,)\n",
      "X_test = (112, 457) ; y_test = (112,)\n"
     ]
    }
   ],
   "source": [
    "# split data into train,test,validation sets\n",
    "\n",
    "X = enriched_df[enriched_df.columns.drop(['recommend'])]\n",
    "y = enriched_df['recommend']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=SEED, shuffle=True) # stratify=y\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.75, random_state=SEED, shuffle=True)\n",
    "\n",
    "print('X_train =', X_train.shape, '; y_train =', y_train.shape)\n",
    "print('X_valid =', X_valid.shape, '; y_valid =', y_valid.shape)\n",
    "print('X_test =', X_test.shape, '; y_test =', y_test.shape)\n",
    "\n",
    "# save to CSV for quick glancing data\n",
    "X_train.to_csv(os.path.join(data_dir, f'user-{today}-cls-train.csv'), index=False)\n",
    "X_valid.to_csv(os.path.join(data_dir, f'user-{today}-cls-valid.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(data_dir, f'user-{today}-cls-test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [False, True, False, False, True, True, False, True, True, True]\n",
      "[[24  7]\n",
      " [15 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.615385  0.774194  0.685714        31\n",
      "        True   0.904110  0.814815  0.857143        81\n",
      "\n",
      "    accuracy                       0.803571       112\n",
      "   macro avg   0.759747  0.794504  0.771429       112\n",
      "weighted avg   0.824195  0.803571  0.809694       112\n",
      "\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 38.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = LogisticRegression(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 175 candidates, totalling 875 fits\n",
      "Best hyperparameters = {'C': 10.0, 'max_iter': 5, 'solver': 'sag'}\n",
      "CPU times: total: 406 ms\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        # 'penalty': ['l2'],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        # 'penalty': ['l1'],\n",
    "        # 'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [5, 10, 25, 50, 100, 250, 500],\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1, n_jobs=4).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, False, True, True, False, True, False, True]\n",
      "[[23  8]\n",
      " [13 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.638889  0.741935  0.686567        31\n",
      "        True   0.894737  0.839506  0.866242        81\n",
      "\n",
      "    accuracy                       0.812500       112\n",
      "   macro avg   0.766813  0.790721  0.776405       112\n",
      "weighted avg   0.823922  0.812500  0.816511       112\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = LogisticRegression(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [False, True, False, False, True, True, False, True, True, True]\n",
      "[[24  7]\n",
      " [21 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.533333  0.774194  0.631579        31\n",
      "        True   0.895522  0.740741  0.810811        81\n",
      "\n",
      "    accuracy                       0.750000       112\n",
      "   macro avg   0.714428  0.757467  0.721195       112\n",
      "weighted avg   0.795274  0.750000  0.761202       112\n",
      "\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = SGDClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 147 candidates, totalling 735 fits\n",
      "Best hyperparameters = {'loss': 'squared_hinge', 'max_iter': 4, 'penalty': 'l2'}\n",
      "CPU times: total: 6.75 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber'],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'max_iter': [2, 4, 8, 16, 32, 64, 128],\n",
    "        # 'learning_rate': ['constant', 'optimal', 'adaptive'],\n",
    "        # 'eta0': [0.5, 1, 2, 4, 8, 16, 32],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [False, True, False, False, True, True, False, True, True, True]\n",
      "[[22  9]\n",
      " [16 65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.578947  0.709677  0.637681        31\n",
      "        True   0.878378  0.802469  0.838710        81\n",
      "\n",
      "    accuracy                       0.776786       112\n",
      "   macro avg   0.728663  0.756073  0.738195       112\n",
      "weighted avg   0.795500  0.776786  0.783068       112\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 18.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = SGDClassifier(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, False, False, False, True, False, False, True, False, True]\n",
      "[[25  6]\n",
      " [26 55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.490196  0.806452  0.609756        31\n",
      "        True   0.901639  0.679012  0.774648        81\n",
      "\n",
      "    accuracy                       0.714286       112\n",
      "   macro avg   0.695918  0.742732  0.692202       112\n",
      "weighted avg   0.787758  0.714286  0.729008       112\n",
      "\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters = {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 20}\n",
      "CPU times: total: 13.4 s\n",
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        'n_neighbors': [5, 10, 15, 20, 25],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size': [10, 20, 30, 40, 50],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [False, False, False, False, False, True, False, False, False, True]\n",
      "[[28  3]\n",
      " [41 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.405797  0.903226  0.560000        31\n",
      "        True   0.930233  0.493827  0.645161        81\n",
      "\n",
      "    accuracy                       0.607143       112\n",
      "   macro avg   0.668015  0.698526  0.602581       112\n",
      "weighted avg   0.785076  0.607143  0.621590       112\n",
      "\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = KNeighborsClassifier(**hyper_best)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, False, False, False, True, True, True, True, False]\n",
      "[[18 13]\n",
      " [22 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.450000  0.580645  0.507042        31\n",
      "        True   0.819444  0.728395  0.771242        81\n",
      "\n",
      "    accuracy                       0.687500       112\n",
      "   macro avg   0.634722  0.654520  0.639142       112\n",
      "weighted avg   0.717187  0.687500  0.698115       112\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best hyperparameters = {'max_depth': 2, 'max_leaf_nodes': 2}\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        # 'criterion': ['gini', 'entropy'],\n",
    "        # 'splitter': ['best', 'random'],\n",
    "        'max_depth': [2, 4, 8, 16, 32],\n",
    "        # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_leaf_nodes': [2, 4, 8, 16, 32],\n",
    "        # 'min_samples_leaf': [1, 2, 3, 4],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, True, True, True, True, True, True, True]\n",
      "[[ 0 31]\n",
      " [ 0 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.000000  0.000000  0.000000        31\n",
      "        True   0.723214  1.000000  0.839378        81\n",
      "\n",
      "    accuracy                       0.723214       112\n",
      "   macro avg   0.361607  0.500000  0.419689       112\n",
      "weighted avg   0.523039  0.723214  0.607050       112\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = DecisionTreeClassifier(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, False, True, True, False, True, True, True]\n",
      "[[15 16]\n",
      " [ 6 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.714286  0.483871  0.576923        31\n",
      "        True   0.824176  0.925926  0.872093        81\n",
      "\n",
      "    accuracy                       0.803571       112\n",
      "   macro avg   0.769231  0.704898  0.724508       112\n",
      "weighted avg   0.793760  0.803571  0.790394       112\n",
      "\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = RandomForestClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best hyperparameters = {'max_depth': 3, 'max_features': 64}\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 4.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        # 'n_estimators': [75, 100, 125],\n",
    "        'max_depth': [1, 3, 5, 7, 9],\n",
    "        'max_features': [8, 16, 32, 64, 128],\n",
    "        # 'max_features': ['sqrt', 'log2', None],\n",
    "        #\n",
    "        # 'criterion': ['gini', 'entropy'],\n",
    "        # 'class_weight': ['balanced', 'balanced_subsample'],\n",
    "        # 'min_samples_split': [10, 15, 25, 50],\n",
    "        # 'min_samples_leaf': [5, 10, 15],\n",
    "        # 'oob_score': [False, True],\n",
    "        # 'max_leaf_nodes': [2, 4, 8, 16, 32, 64]\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1, n_jobs=4).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, True, True, True, True, True, True, True]\n",
      "[[ 2 29]\n",
      " [ 0 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   1.000000  0.064516  0.121212        31\n",
      "        True   0.736364  1.000000  0.848168        81\n",
      "\n",
      "    accuracy                       0.741071       112\n",
      "   macro avg   0.868182  0.532258  0.484690       112\n",
      "weighted avg   0.809334  0.741071  0.646957       112\n",
      "\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = RandomForestClassifier(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, False, False, True, False, True, False, True]\n",
      "[[21 10]\n",
      " [11 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.656250  0.677419  0.666667        31\n",
      "        True   0.875000  0.864198  0.869565        81\n",
      "\n",
      "    accuracy                       0.812500       112\n",
      "   macro avg   0.765625  0.770808  0.768116       112\n",
      "weighted avg   0.814453  0.812500  0.813406       112\n",
      "\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "Best hyperparameters = {'learning_rate': 0.1, 'max_depth': 9, 'max_features': 256, 'n_estimators': 50}\n",
      "CPU times: total: 1.69 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.1, 1, 10],\n",
    "        'n_estimators': [5, 50, 100, 250, 500],\n",
    "        'max_depth': [5, 7, 9, 11, 13],\n",
    "        'max_features': [64, 128, 256],\n",
    "        # 'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
    "        # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1, n_jobs=4).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, False, False, False, True, False, True, False, True]\n",
      "[[23  8]\n",
      " [11 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.676471  0.741935  0.707692        31\n",
      "        True   0.897436  0.864198  0.880503        81\n",
      "\n",
      "    accuracy                       0.830357       112\n",
      "   macro avg   0.786953  0.803067  0.794098       112\n",
      "weighted avg   0.836276  0.830357  0.832672       112\n",
      "\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = GradientBoostingClassifier(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, False, False, False, True, False, True, True, True]\n",
      "[[21 10]\n",
      " [13 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.617647  0.677419  0.646154        31\n",
      "        True   0.871795  0.839506  0.855346        81\n",
      "\n",
      "    accuracy                       0.794643       112\n",
      "   macro avg   0.744721  0.758463  0.750750       112\n",
      "weighted avg   0.801450  0.794643  0.797445       112\n",
      "\n",
      "CPU times: total: 2.16 s\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run with base hyper parameters\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=SEED, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 125 candidates, totalling 625 fits\n",
      "Best hyperparameters = {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "CPU times: total: 28min 27s\n",
      "Wall time: 4min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = None\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
    "        # 'n_estimators': [5, 50, 100, 250, 500],\n",
    "        'max_depth': [1, 3, 5, 7, 9],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=5, verbose=1).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [False, True, False, False, False, True, False, True, True, True]\n",
      "[[20 11]\n",
      " [18 63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.526316  0.645161  0.579710        31\n",
      "        True   0.851351  0.777778  0.812903        81\n",
      "\n",
      "    accuracy                       0.741071       112\n",
      "   macro avg   0.688834  0.711470  0.696307       112\n",
      "weighted avg   0.761386  0.741071  0.748359       112\n",
      "\n",
      "CPU times: total: 9.8 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Try retraining model with new hyperparameters\n",
    "\n",
    "model = xgb.XGBClassifier(**hyper_best, random_state=SEED, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print_model_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
