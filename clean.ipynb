{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean\n",
    "\n",
    "Clean up and remove unnecessary Anilist data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 760 rows\n",
      "anime 16586 rows\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = os.path.abspath('data')\n",
    "# today = datetime.today().strftime('%Y%m%d')\n",
    "today = datetime.strptime('2022-09-27', '%Y-%m-%d').strftime('%Y%m%d')\n",
    "\n",
    "anime_df = pd.read_csv(os.path.join(data_dir, f'anime-{today}-raw.csv'), parse_dates=[8,9]).sort_values('id')\n",
    "user_df = pd.read_csv(os.path.join(data_dir, f'user-{today}-raw.csv'), parse_dates=[4]).sort_values('media_id')\n",
    "\n",
    "print('user', user_df.shape[0], 'rows')\n",
    "print('anime', anime_df.shape[0], 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing User Data:\n",
      "             percent_missing\n",
      "completedAt            15.22\n",
      "\n",
      "Missing Anime Data:\n",
      "                     percent_missing\n",
      "next_airing_episode            98.89\n",
      "title_english                  53.69\n",
      "studios                        45.88\n",
      "season                         34.73\n",
      "season_year                    34.73\n",
      "season_int                     33.44\n",
      "average_score                  32.56\n",
      "tags                           23.81\n",
      "source                         13.79\n",
      "genres                         13.64\n",
      "description                     6.71\n",
      "end_date                        5.67\n",
      "duration_mins                   5.13\n",
      "mean_score                      4.12\n",
      "episodes                        3.80\n",
      "start_date                      2.45\n",
      "title_native                    1.44\n",
      "format                          0.33\n",
      "status                          0.01\n"
     ]
    }
   ],
   "source": [
    "def get_missing(df: DataFrame) -> DataFrame:\n",
    "    df = DataFrame(data=df.isnull().mean().round(4).mul(100).sort_values(ascending=False), columns=['percent_missing'])\n",
    "    return df[df['percent_missing'] > 0]\n",
    "\n",
    "def get_missing_user(df: DataFrame) -> DataFrame:\n",
    "    return get_missing(df[df['status'].isin(['COMPLETED','CURRENT'])])\n",
    "\n",
    "def get_missing_anime(df: DataFrame) -> DataFrame:\n",
    "    df['genres'] = df['genres'].mask(df['genres'] == '[]', None)\n",
    "    df['tags'] = df['tags'].mask(df['tags'] == '[]', None)\n",
    "    df['studios'] = df['studios'].mask(df['studios'] == '[]', None)\n",
    "    return get_missing(df)\n",
    "\n",
    "print(f\"Missing User Data:\\n{get_missing_user(user_df)}\\n\")\n",
    "print(f\"Missing Anime Data:\\n{get_missing_anime(anime_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_user_data(df: DataFrame) -> DataFrame:\n",
    "    df.drop(df[~df['status'].isin(['CURRENT','COMPLETED'])].index, axis=0, inplace=True)\n",
    "    return df.drop(['completedAt','progress'], axis=1, errors='ignore')\n",
    "\n",
    "user_df = clean_user_data(user_df)\n",
    "user_df.to_csv(os.path.join(data_dir, f'user-{today}-clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Anime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_season(dt: datetime) -> str:\n",
    "    if dt.month >= 9 and dt.month <= 11:\n",
    "        return 'FALL'\n",
    "    elif dt.month >= 6 and dt.month <= 8:\n",
    "        return 'SUMMER'\n",
    "    elif dt.month >= 3 and dt.month <= 5:\n",
    "        return 'SPRING'\n",
    "    return 'WINTER'\n",
    "\n",
    "def extract_names(s: str) -> str:\n",
    "    return json.dumps([s['name'].upper() for s in json.loads(s)]) if s else None\n",
    "\n",
    "def extract_episodes(s: str) -> str:\n",
    "    return json.loads(s)['episode'] if s else None\n",
    "\n",
    "def clean_anime_data(df: DataFrame) -> DataFrame:\n",
    "    # drop unusable columns\n",
    "    df.drop([\n",
    "        'title_english', 'title_romaji', 'title_native', 'type', 'description', 'popularity', \n",
    "        'mean_score', 'average_score', 'season_int', 'end_date','duration_mins', 'country'\n",
    "    ], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "    # drop unusable rows\n",
    "    df.drop(df[~df['status'].isin(['FINISHED','RELEASING'])].index, axis=0, inplace=True)\n",
    "    df.drop(df[~df['format'].isin(['TV','MOVIE','SPECIAL','ONA','OVA'])].index, axis=0, inplace=True)\n",
    "\n",
    "    # fix remaining data\n",
    "    df['episodes'] = df['episodes'].fillna(df['next_airing_episode'][df['next_airing_episode'].notna()].apply(extract_episodes))\n",
    "    df['source'] = df['source'].fillna('OTHER')\n",
    "    df['season'] = df['season'].fillna(df['start_date'].apply(fill_season))\n",
    "    df['season_year'] = df['season_year'].fillna(df['start_date'].apply(lambda x: x.year if x else None))\n",
    "    df['studios'] = df['studios'].apply(extract_names)\n",
    "    df['tags'] = df['tags'].apply(extract_names)\n",
    "    df['genres'] = df['genres'].apply(lambda x: x.upper() if x else None)\n",
    "\n",
    "    # drop unusable rows\n",
    "    df.dropna(subset=['episodes','season_year', 'tags', 'genres', 'studios'], inplace=True)\n",
    "\n",
    "    # drop vestigial data\n",
    "    df.drop(['next_airing_episode', 'start_date', 'status', 'media_id'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "    # fix up data types\n",
    "    df['episodes'] = df['episodes'].astype(int)\n",
    "    df['season_year'] = df['season_year'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "anime_df = clean_anime_data(anime_df)\n",
    "anime_df.to_csv(os.path.join(data_dir, f'anime-{today}-clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Missing Data Resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing User Data:\n",
      "Empty DataFrame\n",
      "Columns: [percent_missing]\n",
      "Index: []\n",
      "\n",
      "Missing Anime Data:\n",
      "Empty DataFrame\n",
      "Columns: [percent_missing]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing User Data:\\n{get_missing_user(user_df)}\\n\")\n",
    "print(f\"Missing Anime Data:\\n{get_missing_anime(anime_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Anime and User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data):\n",
      "Empty DataFrame\n",
      "Columns: [percent_missing]\n",
      "Index: []\n",
      "\n",
      "556 rows written\n"
     ]
    }
   ],
   "source": [
    "enriched_df = pd.merge(user_df[user_df['status'].isin(['CURRENT','COMPLETED'])], \n",
    "    anime_df, left_on='media_id', right_on='id', how='inner')\n",
    "enriched_df.drop(['status','media_id'], axis=1, inplace=True)\n",
    "\n",
    "# ensure no unwatched anime included\n",
    "enriched_df.drop(enriched_df[enriched_df['score'] == 0].index, axis=0, inplace=True)\n",
    "print(f\"Missing Data):\\n{get_missing(enriched_df)}\\n\")\n",
    "\n",
    "enriched_df.to_csv(os.path.join(data_dir, f'user-{today}-enriched.csv'), index=False)\n",
    "\n",
    "print(f'{enriched_df.shape[0]}', 'rows written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Data For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 426)\n"
     ]
    }
   ],
   "source": [
    "# binary encode a column\n",
    "#\n",
    "# Note: this could have been achieved this with scikitlearn.preprocessing, \n",
    "# but I wasn't honestly sure how it would like my JSON array columns and\n",
    "# I didn't find any easy answers\n",
    "#\n",
    "def binary_encode(df: DataFrame, col: str) -> DataFrame:\n",
    "    try:\n",
    "        df[col] = df[col].apply(json.loads) # deserialize JSON array\n",
    "    except ValueError: pass\n",
    "\n",
    "    encoded = df.explode(col) # expand categorical data into rows\n",
    "    encoded = pd.concat([df, pd.get_dummies(encoded[col], prefix=col, prefix_sep='_')], axis=1) # convert to indicators\n",
    "    encoded = encoded.groupby('id').max().reset_index() # squash rows\n",
    "    return encoded.drop([col], axis=1) # drop encoded column\n",
    "\n",
    "encoded_df = enriched_df\n",
    "\n",
    "# binary encode each categorical column\n",
    "cols = ['format', 'season', 'source', 'studios', 'genres', 'tags']\n",
    "for col in cols:\n",
    "    encoded_df = binary_encode(encoded_df, col)\n",
    "encoded_df.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "encoded_df.to_csv(os.path.join(data_dir, f'user-{today}-encoded.csv'), index=False)\n",
    "print(encoded_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
