{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Demonstrating a trained model that will be able to classify whether or not I would recommend an anime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# suppress possible unsupported kanji unicode in plots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "data_dir = os.path.abspath('data')\n",
    "\n",
    "# today = datetime.today().strftime('%Y%m%d')\n",
    "today = datetime.strptime('2022-09-27', '%Y-%m-%d').strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = pd.read_csv(os.path.join(data_dir, f'user-{today}-enriched.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encode a column of categorical data\n",
    "def binary_encode(df: DataFrame, col: str) -> DataFrame:\n",
    "    try:\n",
    "        df[col] = df[col].apply(json.loads) # deserialize JSON array\n",
    "    except ValueError: pass\n",
    "    except TypeError:  pass\n",
    "\n",
    "    encoded = df.explode(col) # expand categorical data into rows\n",
    "    encoded = pd.concat([df, pd.get_dummies(encoded[col], prefix=col, prefix_sep='_')], axis=1) # convert to indicators\n",
    "    encoded = encoded.groupby('id').max().reset_index() # squash rows\n",
    "    return encoded.drop([col], axis=1) # drop encoded column\n",
    "\n",
    "def would_recommend(score: int) -> bool:\n",
    "    return score >= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cols = ['genres', 'studios', 'tags', 'source', 'season_year', 'format']\n",
    "\n",
    "# drop unused features\n",
    "enriched_df.drop(['episodes', 'season'], axis=1, inplace=True)\n",
    "\n",
    "# condense scores to three rating levels\n",
    "enriched_df['recommend'] = enriched_df['score'].apply(would_recommend)\n",
    "enriched_df.drop(['score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556, 458)\n"
     ]
    }
   ],
   "source": [
    "# Binary encodes tags,genres,studios. Binary encoding eliminates possible\n",
    "# data leaks that occur with one-hot encoding since it retains one row per entity.\n",
    "\n",
    "# binary encode each categorical column\n",
    "for col in encode_cols:\n",
    "    enriched_df = binary_encode(enriched_df, col)\n",
    "enriched_df.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "print(enriched_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (333, 457) ; y_train = (333,)\n",
      "X_valid = (111, 457) ; y_valid = (111,)\n",
      "X_test = (112, 457) ; y_test = (112,)\n"
     ]
    }
   ],
   "source": [
    "# split data into train,test,validation sets\n",
    "\n",
    "X = enriched_df[enriched_df.columns.drop(['recommend'])]\n",
    "y = enriched_df['recommend']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=SEED, shuffle=True) # stratify=y\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.75, random_state=SEED, shuffle=True)\n",
    "\n",
    "print('X_train =', X_train.shape, '; y_train =', y_train.shape)\n",
    "print('X_valid =', X_valid.shape, '; y_valid =', y_valid.shape)\n",
    "print('X_test =', X_test.shape, '; y_test =', y_test.shape)\n",
    "\n",
    "# save to CSV for quick glancing data\n",
    "X_train.to_csv(os.path.join(data_dir, f'user-{today}-cls-train.csv'), index=False)\n",
    "X_valid.to_csv(os.path.join(data_dir, f'user-{today}-cls-valid.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(data_dir, f'user-{today}-cls-test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Samples:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Prediction Samples:  [True, True, True, False, True, True, False, True, True, True]\n",
      "[[15 16]\n",
      " [ 6 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.714286  0.483871  0.576923        31\n",
      "        True   0.824176  0.925926  0.872093        81\n",
      "\n",
      "    accuracy                       0.803571       112\n",
      "   macro avg   0.769231  0.704898  0.724508       112\n",
      "weighted avg   0.793760  0.803571  0.790394       112\n",
      "\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train with base hyperparameters\n",
    "\n",
    "model = RandomForestClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual Samples:     ', y_test.head(10).tolist())\n",
    "print('Prediction Samples: ', y_pred.tolist()[0:10])\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters = {'max_features': 20, 'n_estimators': 175}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find best hyperparameters\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "hyper_best = {'max_features': 20, 'n_estimators': 175}\n",
    "\n",
    "# Other hyperparameter sets:\n",
    "# hyper_best = {'max_features': 32, 'n_estimators': 100} # 83.04\n",
    "# hyper_best = {'max_features': 24, 'n_estimators': 150} # 83.93\n",
    "# hyper_best = {'max_features': 20, 'n_estimators': 150} # 84.82\n",
    "# hyper_best = {'max_features': 20, 'n_estimators': 175} # 85.71\n",
    "\n",
    "if not hyper_best:\n",
    "    param_grid = {\n",
    "        'n_estimators': [150, 200],\n",
    "        'max_features': [20, 32, 64, 128],\n",
    "    }\n",
    "    hyper_search = GridSearchCV(model, param_grid, cv=3, verbose=1, n_jobs=4).fit(X_valid, y_valid)\n",
    "    hyper_best = hyper_search.best_params_\n",
    "\n",
    "print('Best hyperparameters =', hyper_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:      [True, False, False, False, True, True, False, True, False, True]\n",
      "Predictions: [True, True, True, False, True, True, False, True, True, True]\n",
      "[[19 12]\n",
      " [ 4 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.826087  0.612903  0.703704        31\n",
      "        True   0.865169  0.950617  0.905882        81\n",
      "\n",
      "    accuracy                       0.857143       112\n",
      "   macro avg   0.845628  0.781760  0.804793       112\n",
      "weighted avg   0.854351  0.857143  0.849922       112\n",
      "\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrain model with new hyperparameters\n",
    "\n",
    "model = RandomForestClassifier(**hyper_best, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Actual:     ', y_test.head(10).tolist())\n",
    "print('Predictions:', y_pred.tolist()[0:10])\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
